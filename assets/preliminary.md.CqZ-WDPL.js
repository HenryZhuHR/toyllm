import{_ as e,c as a,o as r,a2 as t}from"./chunks/framework.C50fyHGs.js";const f=JSON.parse('{"title":"大模型相关知识学习记录","description":"","frontmatter":{"lastUpdated":true,"editLink":true,"footer":true,"outline":"deep"},"headers":[],"relativePath":"preliminary.md","filePath":"preliminary.md","lastUpdated":1715750404000}'),n={name:"preliminary.md"},o=t('<h1 id="大模型相关知识学习记录" tabindex="-1">大模型相关知识学习记录 <a class="header-anchor" href="#大模型相关知识学习记录" aria-label="Permalink to &quot;大模型相关知识学习记录&quot;">​</a></h1><h2 id="大模型理论基础" tabindex="-1">大模型理论基础 <a class="header-anchor" href="#大模型理论基础" aria-label="Permalink to &quot;大模型理论基础&quot;">​</a></h2><h3 id="大模型基础组件-tokenizer" tabindex="-1">大模型基础组件 Tokenizer <a class="header-anchor" href="#大模型基础组件-tokenizer" aria-label="Permalink to &quot;大模型基础组件 Tokenizer&quot;">​</a></h3><p>Tokenizer 分词器是 NLP 大模型最基础的组件，基于 Tokenizer 可以将文本转换成独立的 token 列表，进而转换成输入的向量成为计算机可以理解的输入形式。<sup>[<a href="#ref-nghuyong_Tokenizer">1</a>]</sup></p><h2 id="大模型开发框架" tabindex="-1">大模型开发框架 <a class="header-anchor" href="#大模型开发框架" aria-label="Permalink to &quot;大模型开发框架&quot;">​</a></h2><h3 id="transformers" tabindex="-1">transformers <a class="header-anchor" href="#transformers" aria-label="Permalink to &quot;transformers&quot;">​</a></h3><h2 id="参考资料" tabindex="-1">参考资料 <a class="header-anchor" href="#参考资料" aria-label="Permalink to &quot;参考资料&quot;">​</a></h2><ul><li><span id="ref-nghuyong_Tokenizer">[1]</span> <a href="https://zhuanlan.zhihu.com/p/651430181" target="_blank" rel="noreferrer">大模型基础组件 - Tokenizer - nghuyong的文章 - 知乎</a></li></ul>',8),i=[o];function s(l,h,d,c,u,_){return r(),a("div",null,i)}const m=e(n,[["render",s]]);export{f as __pageData,m as default};
